{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Brain tumor\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as data\n",
    "import glob\n",
    "import cv2\n",
    "from torchvision import transforms \n",
    "\n",
    "def random_rot_flip(image, label):\n",
    "    k = np.random.randint(0, 4)\n",
    "    image = np.rot90(image, k)\n",
    "    label = np.rot90(label, k)\n",
    "    axis = np.random.randint(0, 2)\n",
    "    image = np.flip(image, axis=axis).copy()\n",
    "    label = np.flip(label, axis=axis).copy()\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def random_rotate(image, label):\n",
    "    angle = np.random.randint(-20, 20)\n",
    "    image = ndimage.rotate(image, angle, order=0, reshape=False)\n",
    "    label = ndimage.rotate(label, angle, order=0, reshape=False)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "class RandomGenerator(object):\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            image, label = random_rot_flip(image, label)\n",
    "        elif random.random() > 0.5:\n",
    "            image, label = random_rotate(image, label)\n",
    "        x, y = image.shape\n",
    "        if x != self.output_size[0] or y != self.output_size[1]:\n",
    "            image = zoom(image, (self.output_size[0] / x, self.output_size[1] / y), order=3)  # why not 3?\n",
    "            label = zoom(label, (self.output_size[0] / x, self.output_size[1] / y), order=0)\n",
    "        image = torch.from_numpy(image.astype(np.float32)).unsqueeze(0)\n",
    "        label = torch.from_numpy(label.astype(np.float32))\n",
    "        sample = {'image': image, 'label': label.long()}\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Synapse_dataset(Dataset):\n",
    "    def __init__(self, base_dir, list_dir, split, transform=None):\n",
    "        self.transform = transform  # using transform in torch!\n",
    "        self.split = split\n",
    "        self.sample_list = open(os.path.join(list_dir, self.split+'.txt')).readlines()\n",
    "        self.data_dir = base_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == \"train\":\n",
    "            slice_name = self.sample_list[idx].strip('\\n')\n",
    "            data_path = os.path.join(self.data_dir, slice_name+'.npz')\n",
    "            data = np.load(data_path)\n",
    "            image, label = data['image'], data['label']\n",
    "        else:\n",
    "            vol_name = self.sample_list[idx].strip('\\n')\n",
    "            filepath = self.data_dir + \"/{}.npy.h5\".format(vol_name)\n",
    "            data = h5py.File(filepath)\n",
    "            image, label = data['image'][:], data['label'][:]\n",
    "\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        sample['case_name'] = self.sample_list[idx].strip('\\n')\n",
    "        return sample\n",
    "\n",
    "class MriDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, mean=0.5, std=0.25):\n",
    "        super(MriDataset, self).__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.mean = mean\n",
    "        self.std = std        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx, raw=False):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(row['image_filename'], cv2.IMREAD_UNCHANGED)\n",
    "        mask = cv2.imread(row['mask_filename'], cv2.IMREAD_GRAYSCALE)\n",
    "        if raw:\n",
    "            return img, mask\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        mask = mask // 255\n",
    "        mask = torch.Tensor(mask)\n",
    "        # mask = torch.unsqueeze(mask, dim=0)\n",
    "        return img, mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
