{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-j6AGhay8v3r","executionInfo":{"elapsed":16584,"status":"ok","timestamp":1684224560467,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"},"user_tz":-420},"outputId":"cc2ca33b-a7cb-41df-a9be-b7378f6f9a61"},"source":["from google.colab import drive\n"," \n","drive.mount('/content/drive')\n"],"id":"-j6AGhay8v3r","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DEXUsoHu1oD","executionInfo":{"elapsed":7,"status":"ok","timestamp":1684224560468,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"},"user_tz":-420},"outputId":"e9f77765-06b6-446a-bf44-5bcd844004a8"},"source":["%cd '/content/drive/MyDrive/BrainTumorSegmentation_Oct10/'"],"id":"2DEXUsoHu1oD","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BrainTumorSegmentation_Oct10\n"]}]},{"cell_type":"code","metadata":{"id":"1M6U2p3nwpaA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684224566929,"user_tz":-420,"elapsed":6464,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}},"outputId":"17e134d5-8a20-4f70-9269-83d04b84e0d7"},"source":["import os\n","import albumentations as A\n","import cv2\n","import numpy as np\n","from scipy.ndimage.morphology import binary_dilation\n","import torch\n","from torch.nn.functional import sigmoid\n","\n","class EarlyStopping():\n","    \"\"\"\n","    Stops training when loss stops decreasing in a PyTorch module.\n","    \"\"\"\n","    def __init__(self, patience:int = 6, min_delta: float = 0, weights_path: str = 'weights.pt'):\n","        \"\"\"\n","        :param patience: number of epochs of non-decreasing loss before stopping\n","        :param min_delta: minimum difference between best and new loss that is considered\n","            an improvement\n","        :paran weights_path: Path to the file that should store the model's weights\n","        \"\"\"\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.best_loss = float('inf')\n","        self.weights_path = weights_path\n","\n","    def __call__(self, val_loss: float, model: torch.nn.Module):\n","        if self.best_loss - val_loss > self.min_delta:\n","            self.best_loss = val_loss\n","            torch.save(model.state_dict(), self.weights_path)\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True\n","        return False\n","\n","    def load_weights(self, model: torch.nn.Module):\n","        \"\"\"\n","        Loads weights of the best model.\n","        :param model: model to which the weigths should be loaded\n","        \"\"\"\n","        return model.load_state_dict(torch.load(self.weights_path))\n","            \n","\n","def get_file_row(path):\n","    \"\"\"Produces ID of a patient, image and mask filenames from a particular path\"\"\"\n","    path_no_ext, ext = os.path.splitext(path)\n","    filename = os.path.basename(path)\n","    \n","    patient_id = '_'.join(filename.split('_')[:3]) # Patient ID in the csv file consists of 3 first filename segments\n","    \n","    return [patient_id, path, f'{path_no_ext}_mask{ext}']\n","\n","def iou_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n","    \"\"\"Calculates Intersection over Union for a tensor of predictions\"\"\"\n","    predictions = sigmoid(predictions)\n","    predictions = torch.where(predictions > 0.5, 1, 0)\n","    labels = labels.byte()\n","    \n","    intersection = (predictions & labels).float().sum((1, 2))\n","    union = (predictions | labels).float().sum((1, 2))\n","    \n","    iou = (intersection + e) / (union + e)\n","    return iou\n","\n","def dice_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n","    \"\"\"Calculates Dice coefficient for a tensor of predictions\"\"\"\n","    predictions = sigmoid(predictions)\n","    predictions = torch.where(predictions > 0.5, 1, 0)\n","    labels = labels.byte()\n","    \n","    intersection = (predictions & labels).float().sum((1, 2))\n","    return ((2 * intersection) + e) / (predictions.float().sum((1, 2)) + labels.float().sum((1, 2)) + e)    \n","\n","def BCE_dice(output, target, alpha=0.2):\n","    bce = torch.nn.functional.binary_cross_entropy(sigmoid(output), target)\n","    soft_dice = 1 - dice_pytorch(output, target).mean()\n","    return alpha*bce + (1 - alpha) * soft_dice    \n","\n"],"id":"1M6U2p3nwpaA","execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-46dff39665c9>:5: DeprecationWarning: Please use `binary_dilation` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n","  from scipy.ndimage.morphology import binary_dilation\n"]}]},{"cell_type":"code","metadata":{"id":"WOdrM60zvbs7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684224567242,"user_tz":-420,"elapsed":317,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}},"outputId":"9888b26b-9270-4939-fb4f-8f259208ccb4"},"source":["import os\n","import time\n","import albumentations as A\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from scipy.ndimage.morphology import binary_dilation\n","from glob import glob\n","# from data_frame_utils import get_file_row, iou_pytorch, dice_pytorch, BCE_dice, EarlyStopping\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms as T\n","from tqdm import tqdm"],"id":"WOdrM60zvbs7","execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-7e7126856749>:7: DeprecationWarning: Please use `binary_dilation` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n","  from scipy.ndimage.morphology import binary_dilation\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NEpp06dCwxcG","executionInfo":{"elapsed":6524,"status":"ok","timestamp":1684224573764,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"},"user_tz":-420},"outputId":"a37b2d89-8db5-4b74-ba27-0422c47e10aa"},"source":["!pip install ml_collections\n","from networks.vit_seg_modeling import VisionTransformer as ViT_seg\n","from networks.vit_seg_modeling import CONFIGS as CONFIGS_ViT_seg"],"id":"NEpp06dCwxcG","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ml_collections\n","  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml_collections) (1.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml_collections) (6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml_collections) (1.16.0)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml_collections) (0.6.0.post1)\n","Building wheels for collected packages: ml_collections\n","  Building wheel for ml_collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ml_collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=c7d613615e2117b2e0efa2e593c7028a7fd6a7afb7b372f8d85f4848fcdf1106\n","  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n","Successfully built ml_collections\n","Installing collected packages: ml_collections\n","Successfully installed ml_collections-0.1.1\n"]}]},{"cell_type":"code","metadata":{"id":"GmlOckOvxteQ","executionInfo":{"status":"ok","timestamp":1684224575425,"user_tz":-420,"elapsed":1663,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["from TransUNet.datasets.dataset_synapse import MriDataset\n","from TransUNet.networks.vit_seg_modeling import VisionTransformer as ViT_seg\n","from TransUNet.networks.vit_seg_modeling import CONFIGS as CONFIGS_ViT_seg"],"id":"GmlOckOvxteQ","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"NBWKd0WTyoIG","executionInfo":{"status":"ok","timestamp":1684224576162,"user_tz":-420,"elapsed":6,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["def training_loop(writer, epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler):\n","    history = {'train_loss': [], 'val_loss': [], 'val_IoU': [], 'val_dice': []}\n","    early_stopping = EarlyStopping(patience=7)\n","    \n","    for epoch in range(1, epochs + 1):\n","        start_time = time.time()\n","        \n","        running_loss = 0\n","        model.train()\n","        for i, data in enumerate(tqdm(train_loader)):\n","            img, mask = data\n","            img, mask = img.to(device), mask.to(device)\n","            # print(img.shape, mask.shape)\n","            predictions = model(img)\n","            predictions = predictions.squeeze(1)\n","            # print(torch.max(predictions))\n","            loss = loss_fn(predictions, mask)\n","            running_loss += loss.item() * img.size(0)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        \n","        model.eval()\n","        with torch.no_grad():\n","            running_IoU = 0\n","            running_dice = 0\n","            running_valid_loss = 0\n","            for i, data in enumerate(valid_loader):\n","                img, mask = data\n","                img, mask = img.to(device), mask.to(device)\n","                predictions = model(img)\n","                predictions = predictions.squeeze(1)\n","                running_dice += dice_pytorch(predictions, mask).sum().item()\n","                running_IoU += iou_pytorch(predictions, mask).sum().item()\n","                loss = loss_fn(predictions, mask)\n","                running_valid_loss += loss.item() * img.size(0)\n","        train_loss = running_loss / len(train_loader.dataset)\n","        val_loss = running_valid_loss / len(valid_loader.dataset)\n","        val_dice = running_dice / len(valid_loader.dataset)\n","        val_IoU = running_IoU / len(valid_loader.dataset)\n","        \n","        history['train_loss'].append(train_loss)\n","        writer.add_scalar(\"Training/Train loss\", train_loss, epoch)\n","        writer.add_scalar(\"Training/Val loss\", val_loss, epoch)\n","        writer.add_scalar(\"Metric/Val IoU\", val_IoU, epoch)\n","        writer.add_scalar(\"Metric/Val Dice\", val_dice, epoch)\n","\n","        history['val_loss'].append(val_loss)\n","        history['val_IoU'].append(val_IoU)\n","        history['val_dice'].append(val_dice)\n","        print(f'Epoch: {epoch}/{epochs} | Training loss: {train_loss} | Validation loss: {val_loss} | Validation Mean IoU: {val_IoU} '\n","         f'| Validation Dice coefficient: {val_dice}')\n","        \n","        lr_scheduler.step(val_loss)\n","        if early_stopping(val_loss, model):\n","            early_stopping.load_weights(model)\n","            break\n","    model.eval()\n","    return history\n"],"id":"NBWKd0WTyoIG","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZdJej4c3PDi","executionInfo":{"status":"ok","timestamp":1684224576162,"user_tz":-420,"elapsed":5,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["# https://drive.google.com/drive/folders/1YxaM1yS6m_zuzmGZDSNjXeN6vNFeqyRK\n","mri_data='/content/drive/MyDrive/Brain_Tumor/input/lgg-mri-segmentation/kaggle_3m/'"],"id":"SZdJej4c3PDi","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLjtMRtp3nuX","executionInfo":{"status":"ok","timestamp":1684224594180,"user_tz":-420,"elapsed":18022,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","csv_path = mri_data+'data.csv'\n","files_dir =mri_data\n","file_paths = glob(f'{files_dir}/*/*[0-9].tif')\n","df = pd.read_csv(csv_path)\n","imputer = SimpleImputer(strategy=\"most_frequent\")\n","df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"],"id":"tLjtMRtp3nuX","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdo6e0ek3-Nc","executionInfo":{"status":"ok","timestamp":1684224594181,"user_tz":-420,"elapsed":15,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["filenames_df = pd.DataFrame((get_file_row(filename) for filename in file_paths), columns=['Patient', 'image_filename', 'mask_filename'])\n","df = pd.merge(df, filenames_df, on=\"Patient\")\n","train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n","test_df, valid_df = train_test_split(test_df, test_size=0.5, random_state=42)"],"id":"kdo6e0ek3-Nc","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8misPm1n4BT4","executionInfo":{"elapsed":3854,"status":"ok","timestamp":1684224598021,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"},"user_tz":-420},"outputId":"68034a2b-b594-40d5-dd12-33129fdfb96e"},"source":["!pip install tensorboardX"],"id":"8misPm1n4BT4","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/114.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n","Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6\n"]}]},{"cell_type":"code","metadata":{"id":"JjDLlG-g4VKV","executionInfo":{"status":"ok","timestamp":1684224598021,"user_tz":-420,"elapsed":19,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["from tensorboardX import SummaryWriter\n","writer = SummaryWriter(\"tensorboard_logs\")"],"id":"JjDLlG-g4VKV","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAErrqnW4PPH","executionInfo":{"status":"ok","timestamp":1684224598022,"user_tz":-420,"elapsed":19,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["transform = A.Compose([A.ChannelDropout(p=0.3),A.RandomBrightnessContrast(p=0.3),A.ColorJitter(p=0.3),])"],"id":"OAErrqnW4PPH","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"z2whH2gz4vZ2","executionInfo":{"status":"ok","timestamp":1684224598022,"user_tz":-420,"elapsed":18,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["# train_dataset = MriDataset(train_df, transform)\n","train_dataset = MriDataset(train_df)\n","valid_dataset = MriDataset(valid_df)\n","test_dataset = MriDataset(test_df)"],"id":"z2whH2gz4vZ2","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-Z8q-ER40U5","executionInfo":{"status":"ok","timestamp":1684224598022,"user_tz":-420,"elapsed":17,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":[],"id":"6-Z8q-ER40U5","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"GiE1zljm4Pot","executionInfo":{"status":"ok","timestamp":1684224598022,"user_tz":-420,"elapsed":17,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["batch_size = 8\n","img_size = 256\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1)\n","config_vit = CONFIGS_ViT_seg[\"R50-ViT-B_16\"]\n","config_vit.n_classes = 1\n","config_vit.n_skip = 3\n"],"id":"GiE1zljm4Pot","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DABqxGq57CPN","executionInfo":{"elapsed":15457,"status":"ok","timestamp":1684224613462,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"},"user_tz":-420},"outputId":"426e35d4-cd59-44a7-9d78-8c78a53b79b5"},"source":["!wget https://storage.googleapis.com/vit_models/imagenet21k/R50+ViT-B_16.npz "],"id":"DABqxGq57CPN","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-16 08:09:58--  https://storage.googleapis.com/vit_models/imagenet21k/R50+ViT-B_16.npz\n","Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.128.128, 74.125.124.128, 172.217.212.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.128.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 461217452 (440M) [application/octet-stream]\n","Saving to: ‘R50+ViT-B_16.npz.1’\n","\n","R50+ViT-B_16.npz.1  100%[===================>] 439.85M  31.8MB/s    in 14s     \n","\n","2023-05-16 08:10:13 (31.0 MB/s) - ‘R50+ViT-B_16.npz.1’ saved [461217452/461217452]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgCqzLef7GJG","outputId":"632b9eab-7e47-4007-a23c-f75f4538cda2","executionInfo":{"status":"ok","timestamp":1684235067549,"user_tz":-420,"elapsed":2657317,"user":{"displayName":"Cương Nguyễn Đăng","userId":"14437272950741315063"}}},"source":["model = ViT_seg(config_vit, img_size=img_size, num_classes=config_vit.n_classes).cuda()\n","# weight = np.load('../model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz')\n","weight = np.load('R50+ViT-B_16.npz')\n","model.load_from(weights=weight)\n","\n","optimizer = Adam(model.parameters(), lr=0.005)\n","epochs = 100\n","lr_scheduler = ReduceLROnPlateau(optimizer=optimizer, patience=2,factor=0.1)\n","loss_fn = BCE_dice\n","history = training_loop(writer, epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler)"],"id":"xgCqzLef7GJG","execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 28/100 | Training loss: 0.05809656541459778 | Validation loss: 0.09827528504117207 | Validation Mean IoU: 0.8454220998085151 | Validation Dice coefficient: 0.8787152710607496\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 29/100 | Training loss: 0.05496762559579061 | Validation loss: 0.09565662667786672 | Validation Mean IoU: 0.849231250407332 | Validation Dice coefficient: 0.8820126695148015\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 30/100 | Training loss: 0.053607974891671226 | Validation loss: 0.09782857329091867 | Validation Mean IoU: 0.8464731006299036 | Validation Dice coefficient: 0.879276500313969\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 31/100 | Training loss: 0.054419648057992494 | Validation loss: 0.09720521357731293 | Validation Mean IoU: 0.8468482623666019 | Validation Dice coefficient: 0.8800474255771961\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 32/100 | Training loss: 0.05599526549473475 | Validation loss: 0.09630805831876094 | Validation Mean IoU: 0.8478387371968414 | Validation Dice coefficient: 0.8811972731250828\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 33/100 | Training loss: 0.054573893992902 | Validation loss: 0.094902740052696 | Validation Mean IoU: 0.8498085030054642 | Validation Dice coefficient: 0.8829386412087133\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 34/100 | Training loss: 0.05375122954743413 | Validation loss: 0.0966704132445788 | Validation Mean IoU: 0.8476023779077045 | Validation Dice coefficient: 0.8807310160944017\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 35/100 | Training loss: 0.05449831532925865 | Validation loss: 0.09678663690969096 | Validation Mean IoU: 0.8475285691730047 | Validation Dice coefficient: 0.8805896371097888\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 36/100 | Training loss: 0.053800759506549105 | Validation loss: 0.09600555979955293 | Validation Mean IoU: 0.8482875775482694 | Validation Dice coefficient: 0.8815690816459009\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 37/100 | Training loss: 0.054189440330347595 | Validation loss: 0.0962824126547676 | Validation Mean IoU: 0.8480597665754416 | Validation Dice coefficient: 0.8812073141841565\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 38/100 | Training loss: 0.053620310550569476 | Validation loss: 0.09531656396672696 | Validation Mean IoU: 0.8494129423367776 | Validation Dice coefficient: 0.882422973341861\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 39/100 | Training loss: 0.054738486923258854 | Validation loss: 0.09535883420191983 | Validation Mean IoU: 0.8492475671283269 | Validation Dice coefficient: 0.8823637008666992\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344/344 [03:18<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 40/100 | Training loss: 0.05393441031455156 | Validation loss: 0.09694806170722339 | Validation Mean IoU: 0.8473347429501809 | Validation Dice coefficient: 0.880387417744782\n"]}]}]}